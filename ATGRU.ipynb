{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM+GJTcO/LSg0yh0t+rz/71"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-33E9aMlrOR_","executionInfo":{"status":"ok","timestamp":1708404501796,"user_tz":-360,"elapsed":819556,"user":{"displayName":"Ameya Debnath","userId":"03238844752105508856"}},"outputId":"17732c06-c0f2-453f-c73e-9671b11df5fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","110/110 [==============================] - 87s 750ms/step - loss: 0.6012 - accuracy: 0.7056 - val_loss: 0.4533 - val_accuracy: 0.8110\n","Epoch 2/10\n","110/110 [==============================] - 81s 737ms/step - loss: 0.3022 - accuracy: 0.8843 - val_loss: 0.2842 - val_accuracy: 0.8797\n","Epoch 3/10\n","110/110 [==============================] - 78s 712ms/step - loss: 0.0929 - accuracy: 0.9688 - val_loss: 0.3320 - val_accuracy: 0.8820\n","Epoch 4/10\n","110/110 [==============================] - 78s 710ms/step - loss: 0.0359 - accuracy: 0.9908 - val_loss: 0.3830 - val_accuracy: 0.8958\n","Epoch 5/10\n","110/110 [==============================] - 80s 724ms/step - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.3975 - val_accuracy: 0.8923\n","Epoch 6/10\n","110/110 [==============================] - 81s 738ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.4529 - val_accuracy: 0.8969\n","Epoch 7/10\n","110/110 [==============================] - 81s 739ms/step - loss: 0.0092 - accuracy: 0.9977 - val_loss: 0.4740 - val_accuracy: 0.8981\n","Epoch 8/10\n","110/110 [==============================] - 80s 726ms/step - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.4864 - val_accuracy: 0.8900\n","Epoch 9/10\n","110/110 [==============================] - 80s 733ms/step - loss: 0.0066 - accuracy: 0.9983 - val_loss: 0.5002 - val_accuracy: 0.8900\n","Epoch 10/10\n","110/110 [==============================] - 80s 724ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.4971 - val_accuracy: 0.8992\n","35/35 [==============================] - 6s 165ms/step\n","35/35 [==============================] - 5s 134ms/step - loss: 0.3377 - accuracy: 0.9185\n","Test Loss: 0.3377, Test Accuracy: 91.85%\n","Target 1 Metrics:\n","  Accuracy: 91.57%\n","  Precision: 0.8571\n","  Recall: 0.8889\n","  F1 Score: 0.8727\n","Target 0 Metrics:\n","  Accuracy: 50.00%\n","  Precision: 0.0000\n","  Recall: 0.0000\n","  F1 Score: 0.0000\n","Target 5 Metrics:\n","  Accuracy: 90.00%\n","  Precision: 1.0000\n","  Recall: 0.7500\n","  F1 Score: 0.8571\n","Target 3 Metrics:\n","  Accuracy: 91.67%\n","  Precision: 0.9091\n","  Recall: 0.7895\n","  F1 Score: 0.8451\n","Target 4 Metrics:\n","  Accuracy: 100.00%\n","  Precision: 0.0000\n","  Recall: 0.0000\n","  F1 Score: 0.0000\n","Target 2 Metrics:\n","  Accuracy: 66.67%\n","  Precision: 0.5000\n","  Recall: 1.0000\n","  F1 Score: 0.6667\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1609: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"]}],"source":["#Bi-directional Gated Recurrent Unit Neural Network with token Level Attention Mechanism\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, Bidirectional, GRU, Dense, Attention, Concatenate\n","from tensorflow.keras.layers import GlobalMaxPooling1D\n","\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Load your dataset\n","df = pd.read_csv('/content/final_dataset - Sheet1.csv')\n","\n","# Split the data into training and testing sets\n","train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n","\n","# Tokenize the comments\n","max_words = 10000\n","tokenizer = Tokenizer(num_words=max_words, oov_token='<OOV>')\n","tokenizer.fit_on_texts(train_df['Comment'])\n","\n","# Convert comments to sequences\n","train_sequences = tokenizer.texts_to_sequences(train_df['Comment'])\n","test_sequences = tokenizer.texts_to_sequences(test_df['Comment'])\n","\n","# Pad sequences\n","max_sequence_length = max(len(seq) for seq in train_sequences)\n","X_train = pad_sequences(train_sequences, maxlen=max_sequence_length)\n","X_test = pad_sequences(test_sequences, maxlen=max_sequence_length)\n","\n","# Prepare target data\n","y_train = np.array(train_df['Stance'])\n","y_test = np.array(test_df['Stance'])\n","\n","# Prepare target-specific information\n","target_info_train = np.array(train_df['Target'])\n","target_info_test = np.array(test_df['Target'])\n","\n","# Build ATGRU model\n","embedding_dim = 100\n","\n","# Input layers\n","input_comment = Input(shape=(max_sequence_length,), name='input_comment')\n","input_target = Input(shape=(1,), name='input_target')\n","\n","# Embedding layer for comments\n","embedding_layer = Embedding(input_dim=max_words, output_dim=embedding_dim)(input_comment)\n","\n","# Bidirectional GRU layer\n","gru_layer = Bidirectional(GRU(64, return_sequences=True))(embedding_layer)\n","\n","# Attention layer\n","# attention_layer = Attention()([gru_layer, tf.tile(tf.expand_dims(input_target, axis=1), multiples=[1, max_sequence_length, 1])])\n","attention_layer = Attention()([gru_layer, tf.tile(tf.expand_dims(input_target, axis=-1), multiples=[1, 1, 128])])\n","\n","\n","# Concatenate attention output with target information\n","merged_layer = Concatenate()([gru_layer, attention_layer])\n","\n","# GlobalMaxPooling1D layer\n","global_max_pooling_layer = GlobalMaxPooling1D()(merged_layer)\n","\n","# Dense layers\n","dense_layer = Dense(32, activation='relu')(global_max_pooling_layer)\n","output_layer = Dense(1, activation='sigmoid', name='output')(dense_layer)\n","\n","# Build and compile the model\n","model = Model(inputs=[input_comment, input_target], outputs=output_layer)\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit([X_train, target_info_train], y_train, epochs=10, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model on the test set\n","y_pred = model.predict([X_test, target_info_test])\n","y_pred_binary = (y_pred > 0.5).astype(int)\n","\n","# Overall metrics\n","test_loss, test_accuracy = model.evaluate([X_test, target_info_test], y_test)\n","print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy * 100:.2f}%')\n","\n","# Calculate metrics for each target class\n","unique_targets = df['Target'].unique()\n","\n","for target_class in unique_targets:\n","    indices = test_df[test_df['Target'] == target_class].index\n","    indices = indices[indices < len(y_test)]  # Ensure indices are within bounds\n","\n","    y_test_target = y_test[indices]\n","    y_pred_target = y_pred_binary[indices]\n","\n","    accuracy = accuracy_score(y_test_target, y_pred_target)\n","    precision = precision_score(y_test_target, y_pred_target)\n","    recall = recall_score(y_test_target, y_pred_target)\n","    f1 = f1_score(y_test_target, y_pred_target)\n","\n","    print(f'Target {target_class} Metrics:')\n","    print(f'  Accuracy: {accuracy * 100:.2f}%')\n","    print(f'  Precision: {precision:.4f}')\n","    print(f'  Recall: {recall:.4f}')\n","    print(f'  F1 Score: {f1:.4f}')\n"]}]}